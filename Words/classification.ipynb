{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3160aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2936ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb82a277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20305 entries, 0 to 20304\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  20305 non-null  int64 \n",
      " 1   Text        20305 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 317.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f01821b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f16f784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>azərbaycan erməni ara son döyük harada ged ətr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>son məlumat azərbaycan kor infeksiya yeni yolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baş nazik müavin şahin Mustafayev gün tehran i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qış ev isti saxlama sadə ucuz üsulu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iraq rəsmi xəbər agentlik irq türkmən paytaxt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>azərbaycan baş nazir müavin şahin Mustafayev i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>min əhali olan mar şəhər i məktəb sayəsində zə...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kor simptom haqqında getdikcə məlumat ək edil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>türki hərbi təyyarə proqram çıxarıl ab yeni f ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>talib hakimiyyət gələn minlərlə əfqan qaçqın t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  azərbaycan erməni ara son döyük harada ged ətr...\n",
       "1  son məlumat azərbaycan kor infeksiya yeni yolu...\n",
       "2  baş nazik müavin şahin Mustafayev gün tehran i...\n",
       "3                qış ev isti saxlama sadə ucuz üsulu\n",
       "4  iraq rəsmi xəbər agentlik irq türkmən paytaxt ...\n",
       "5  azərbaycan baş nazir müavin şahin Mustafayev i...\n",
       "6  min əhali olan mar şəhər i məktəb sayəsində zə...\n",
       "7  kor simptom haqqında getdikcə məlumat ək edil ...\n",
       "8  türki hərbi təyyarə proqram çıxarıl ab yeni f ...\n",
       "9  talib hakimiyyət gələn minlərlə əfqan qaçqın t..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646dac84",
   "metadata": {},
   "source": [
    "# Categories:\n",
    "## First\n",
    "\n",
    "#### Positive:\n",
    "uğurlu, bilik, təhsil, incəsənət, bayram, festival, mübarək, apple pay, google pay, humanitar yardım, \n",
    "orden, medal, \n",
    "\n",
    "\n",
    "#### Negative:\n",
    "cinayət, polis, təəssüf, fövqəladə, yanğın, erməni, cəbhə, repressiya, mitinq, xəstəlik, nikol, cənazə\n",
    "\n",
    "\n",
    "#### Neutral:\n",
    "Paşa, yelo, abb, kapital bank, kart, iqtisadi, pul, metro\n",
    "\n",
    "## Second:\n",
    "#### Politics:\n",
    "milli məclis, hökumətlərarası, azərbaycan, qondarma, iqtisadi, mitinq, erməni, sülh, bəyannamə, prezident,\n",
    "\n",
    "\n",
    "#### Banking:\n",
    "yelo, bank, kredit, müştəri, apple\n",
    "\n",
    "#### Culture:\n",
    "mədəniyyət, şeir, poeziya, repressiya, sərgi, incəsənət, festival, sənətkar, bəstəkar, rəssam,\n",
    "\n",
    "\n",
    "#### Education:\n",
    "təhsil, tələbə, şagird, universitet, məktəb, əlifba\n",
    "\n",
    "#### Sport:\n",
    "\n",
    "#### Military:\n",
    "ordu, rəşadətli, orden, medal, \n",
    "\n",
    "#### Econimics\n",
    "iqtisadi, kart, bank, pul, manat, sərmayə\n",
    "\n",
    "#### Other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10ff3377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "milli arxiv idarə növbəti vebin keçiril\n",
      "---------------------------------\n",
      "azərbaycan respublika iqtisadiyyat nazirlik yapon nippo ixrac investisiya sığorta şirkət nex ara ümumi əməkdaşlıq haqqında anlaşma imzalan ətraflı azərbaycan yapon econom economaz\n",
      "---------------------------------\n",
      "beşik ser fbvbj\n",
      "---------------------------------\n",
      "shaig salam həmvətənli düşün bak ukrayn ərazi olan azərbaycan vətəndaş balans az vəsait yüklə dəyərli təklif biz bölüş təşəkkür edi hansı yenilik nəzər məlumat təqdim olun\n",
      "---------------------------------\n",
      "i illik yubiley dair mətbuat konfrans keçiril ətraf il economicreform press iqtisadiyyat az ye\n",
      "---------------------------------\n",
      "eipvqyeomiu gündəlik xidməti haqq az kampaniya şəbəkə dəqiqə təqdim edil kampaniya gün yenilən təqdim edilə dəqiqə yalnız bölgə şəbəkə zəng istifadə edilə bil kampaniya fakturasız xətt nömrələ üç\n",
      "---------------------------------\n",
      "gün dahi qəzəlxan doğum günü\n",
      "---------------------------------\n",
      "açıqlama rusi məlumat təəccüb təəssüf doğur deyil bildiril iddia azərbaycan m nümayəndə rusi sülhməramlı rəhbər birgə iştirak araşdırıl həmin tarik istiqamət bölmə hansı atəş açma təsbit olun\n",
      "---------------------------------\n",
      "rusi ordu aprel od raket vur nəticədə dinc əhali nəfər həlak ol sayda yaralı həlak olan biri aylıq körpə prezident z z cinayət reaksiya murdarla aylıq körpə öldür\n",
      "---------------------------------\n",
      "erməni parlament növbəti qalmaqal er iğtişaş parlament dava\n"
     ]
    }
   ],
   "source": [
    "def returnRandom10Line(df = df):\n",
    "    random_numbers = [random.randint(0, df.shape[0]) for _ in range(10)]\n",
    "    for idx in random_numbers:\n",
    "        print(\"---------------------------------\")\n",
    "        print(df.loc[idx, 'Text'])\n",
    "    \n",
    "returnRandom10Line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26bd7541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterRows(df = df):\n",
    "    df_copy = df.copy()\n",
    "    df_copy = df_copy[df_copy['Text'].str.split().str.len() > 5]\n",
    "    print(\"Number of droppend rows:\", df.shape[0] - df_copy.shape[0])\n",
    "    return df_copy.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9700788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of droppend rows: 1770\n"
     ]
    }
   ],
   "source": [
    "res = filterRows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32f20862",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = ['uğurlu', 'bilik', 'təhsil', 'incəsənət', 'bayram', 'festival', 'mübarək', 'apple pay', \n",
    "                  'google pay', 'humanitaryardım', 'orden', 'medal', 'bacarıq', 'macəraçı', 'mehriban', \n",
    "                  'razı', 'iddialı', 'mehriban', 'əyləncəli', 'cəsur', 'parlaq', 'sakit', 'bacarıqlı', \n",
    "                  'cazibədar', 'şən', 'ağıllı', 'mərhəmətli', 'inamlı', 'fikirli', 'cəsarətli', \n",
    "                  'nəzakətli', 'yaradıcı', 'etibarlı', 'cəsarətli', 'gözqamaşdırıcı', 'zərif', 'ləzzətli', \n",
    "                  'çalışqan', 'diplomatik', 'təmkinli', 'dinamik', 'istəkli', 'ciddi', 'yolagedən', \n",
    "                  'səmərəli', 'zərif', 'elit', 'empatik', 'enerjili', 'həvəsli', 'vacib', 'əla', \n",
    "                  'həyəcanlı', 'ekspert', 'qeyri-adi', 'ədalətli', 'sadiq', 'fantastik', 'qorxmaz', \n",
    "                  'yaxşı', 'gülməli', 'zərif', 'şanlı', 'yaxşı', 'mərhəmətli', 'xoşbəxt', 'harmonik', \n",
    "                  'faydalı', 'dürüst', 'hörmətli', 'ideal', 'inanılmaz', 'yenilikçi', 'ixtiraçı', \n",
    "                  'şən', 'mehriban', 'bilikli', 'lider', 'əfsanəvi', 'işıq', 'sadiq', 'şanslı', \n",
    "                  'möhtəşəm', 'möcüzə', 'yumşaq', 'motivasiyalı', 'təbii', 'gözəl', \n",
    "                  'optimist', 'görkəmli', 'zəhmətkeş', 'ehtiraslı', 'dinc', 'mükəmməl', 'səbirli', \n",
    "                  'davamlı', 'xeyriyyəçi', 'fəlsəfi', 'sakit', 'cəld', 'məşhur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6438961",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = ['təsdiqləmək', 'şaqqal', 'xəbislik', 'xırtıldayan', 'uçurumlu', 'çürük', 'vəhşi', \n",
    "                  'mitinq', 'təəssüf', 'zəhlətökən', 'ümidsizlik', 'dəhşətli', 'iyrənc', 'cənazə', \n",
    "                  'bədbəxtlik', 'qorxu', 'sinizm', 'xaç', 'travma', 'xoşagəlməz', 'acı', 'rüsvayçılıq', \n",
    "                  'xəstəlik', 'qeyri-qənaətbəxş', 'qüsurlu', 'əhvalsız', 'pislik', 'günahkarlıq', 'terror', \n",
    "                  'kədər', 'depressiya', 'ən pis', 'utanmaq', 'qəzəbli', 'utandırıcı', 'dep efir', 'polis', \n",
    "                  'tənqid etmək', 'travmatik', 'səfalət', 'erməni', 'çarəsiz', 'yanğın', 'bədbəxt', \n",
    "                  'düşmənçilik', 'yazıq', 'cəbhə', 'xəstəlikverici', 'məyusedici', 'kədərləndirici', \n",
    "                  'üsyankar', 'narahat', 'nifrət', 'qıcıqlandırıcı', 'kədərli', 'güllük', 'qorxunc', \n",
    "                  'pis', 'narahatçılıq', 'fövqəladə', 'peşiman', 'günahkar', 'nikol', 'çirkin', \n",
    "                  'peşmanlıq', 'kinik', 'qınamaq', 'hücumedici', 'çarəsizlik', 'qıcıqlanan', 'incidici', \n",
    "                  'qorxulu', 'cinayət', 'repressiya', 'melanxolik', 'alçaq', 'narahatlıq', 'kinbaz', \n",
    "                  'etibarsızlıq', 'qeyri-adi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ee7cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_words = ['Paşa', 'yelo', 'abb', 'kapital bank', 'kart', 'iqtisadi', 'pul', 'metro', 'diqqətli',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a32373bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addClass(df = df):\n",
    "    data = df.copy()\n",
    "    final = pd.DataFrame(data = {'Text':[], 'class': []})\n",
    "    data['class'] = 'n/a'\n",
    "    print(f'Length of all data {data.shape[0]}')\n",
    "    \n",
    "    data['class'] = data['Text'].apply(lambda x: any(x.find(f' {word} ')>=0 for word in positive_words))\n",
    "    data.loc[data['class'] == True, 'class'] = 'positive'\n",
    "    positive_converted = data[data[\"class\"] == 'positive'].shape[0]\n",
    "    positives = data[data[\"class\"] == 'positive']\n",
    "    final = pd.concat([positives, final], axis = 0)\n",
    "    print(f'{positive_converted} converted, {data.shape[0] - positive_converted} remaining')\n",
    "    data = data[data['class'] != 'positive']\n",
    "    \n",
    "    data['class'] = data['Text'].apply(lambda x: any(x.find(f' {word} ')>=0 for word in negative_words))\n",
    "    \n",
    "    data.loc[data['class'] == True, 'class'] = 'negative'\n",
    "    negative_converted = data[data[\"class\"] == 'negative'].shape[0]\n",
    "    negatives = data[data[\"class\"] == 'negative']\n",
    "    final = pd.concat([negatives, final], axis = 0)\n",
    "    print(f'{negative_converted} converted, {data.shape[0] - negative_converted} remaining')\n",
    "    data = data[data['class'] != 'negative']\n",
    "    \n",
    "    data['class'] = data['Text'].apply(lambda x: any(x.find(f' {word} ')>=0 for word in neutral_words))\n",
    "    data.loc[data['class'] == True, 'class'] == 'neutral'\n",
    "    neutral_converted = data[data[\"class\"] == 'neutral'].shape[0]\n",
    "    negatives = data[data[\"class\"] == 'neutral']\n",
    "    final = pd.concat([negatives, final], axis = 0)\n",
    "    print(f'{neutral_converted} converted, {data.shape[0] - neutral_converted} remaining')\n",
    "    data = data[data['class'] != 'neutral']\n",
    "    \n",
    "    print(f'Length of data {data.shape[0]}')\n",
    "    print(f'Length of final {final.shape[0]}')\n",
    "    \n",
    "    return final.reset_index(drop=True), data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7b443d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of all data 20305\n",
      "2978 converted, 17327 remaining\n",
      "1484 converted, 15843 remaining\n",
      "0 converted, 15843 remaining\n",
      "Length of data 15843\n",
      "Length of final 4462\n"
     ]
    }
   ],
   "source": [
    "final, data = addClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4454fa95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b hökümət ölkə xaric gəlmə vurulan vaksinlə siyahı genişləndir london yaşıl işıq ver vaksin siyahı noyabr dən etibarən sinov olacaq astra pfizer yoxsa sinov hansı yaxşı'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[final['class'] == 'positive']['Text'].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc2f375c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m final\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Analysis/result.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      2\u001b[0m              index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "final.to_csv(f'{os.path.abspath(os.path.join(os.path.dirname(__file__),\"..\"))}/Analysis/result.csv', \n",
    "             index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5885385",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m script_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m))\n\u001b[1;32m      2\u001b[0m parent_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(script_dir, os\u001b[38;5;241m.\u001b[39mpardir))\n\u001b[1;32m      3\u001b[0m analysis_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(parent_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnalysis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "parent_dir = os.path.abspath(os.path.join(script_dir, os.pardir))\n",
    "analysis_dir = os.path.join(parent_dir, 'Analysis')\n",
    "if not os.path.exists(analysis_dir):\n",
    "    os.makedirs(analysis_dir)\n",
    "final.to_csv(os.path.join(analysis_dir, 'result.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd37f432",
   "metadata": {},
   "source": [
    "Have to divide the list with priority\n",
    "\n",
    "The order of defining class can be important\n",
    "\n",
    "Maybe not dropping the rows adding all classes to all rows to see"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
